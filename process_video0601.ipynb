{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ffmpeg-python  -version\n",
    "# !ffprobe -version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install opencv-python\n",
    "# !pip install moviepy\n",
    "# !pip install ffmpeg-pytho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def apply_effect_to_frame(frame, effect_func):\n",
    "#     # 在这里应用特效函数\n",
    "#     effect_func(frame)\n",
    "\n",
    "# def process_frames_in_time_range(video_path, start_time_minutes, start_time_seconds, end_time_minutes, end_time_seconds, effect_func, batch_size=100):\n",
    "#     cap = cv2.VideoCapture(video_path)\n",
    "#     fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "#     start_time_in_seconds = start_time_minutes * 60 + start_time_seconds\n",
    "#     end_time_in_seconds = end_time_minutes * 60 + end_time_seconds\n",
    "#     start_frame = int(start_time_in_seconds * fps)\n",
    "#     end_frame = int(end_time_in_seconds * fps)\n",
    "\n",
    "#     cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "#     processed_frames = start_frame\n",
    "#     frame_buffer = []\n",
    "    \n",
    "#     while cap.isOpened():\n",
    "#         ret, frame = cap.read()\n",
    "#         if not ret or processed_frames > end_frame:\n",
    "#             break\n",
    "#         frame_buffer.append(frame)\n",
    "#         processed_frames += 1\n",
    "#         if len(frame_buffer) == batch_size or processed_frames == end_frame + 1:\n",
    "#             print(f\"處理帧 {start_frame}到{processed_frames - 1}，總帧數: {end_frame - start_frame + 1}\")\n",
    "#             for i, frame in enumerate(frame_buffer):\n",
    "#                 processed_frame = effect_func(frame)\n",
    "#                 frame_filename = f\"{frames_folder}/frame_{start_frame + i:04d}.png\"\n",
    "#                 cv2.imwrite(frame_filename, processed_frame)\n",
    "#             frame_buffer = []\n",
    "    \n",
    "#     cap.release()\n",
    "#     print(f\"輸入時間: {start_time_minutes}分{start_time_seconds}秒 到 {end_time_minutes}分{end_time_seconds}秒\")\n",
    "#     print(f\"輸出帧範圍: 第{start_frame}帧到第{processed_frames - 1}帧\")\n",
    "#     return start_frame, processed_frames - 1\n",
    "\n",
    "# def process_frames_with_effect(video_path, time_effects):\n",
    "#     for (start_min, start_sec, end_min, end_sec), effect_func in time_effects.items():\n",
    "#         process_frames_in_time_range(video_path, start_min, start_sec, end_min, end_sec, effect_func)\n",
    "\n",
    "\n",
    "# def split_video(video_path, output_folder, batch_size=30):\n",
    "#     if not os.path.exists(output_folder):\n",
    "#         os.makedirs(output_folder)\n",
    "    \n",
    "#     cap = cv2.VideoCapture(video_path)\n",
    "#     frame_number = 0\n",
    "#     frame_buffer = []\n",
    "    \n",
    "#     while cap.isOpened():\n",
    "#         ret, frame = cap.read()\n",
    "#         if not ret:\n",
    "#             break\n",
    "#         frame_buffer.append(frame)\n",
    "#         if len(frame_buffer) == batch_size:\n",
    "#             for i, frame in enumerate(frame_buffer):\n",
    "#                 frame_filename = f\"{output_folder}/frame_{frame_number + i:04d}.png\"\n",
    "#                 cv2.imwrite(frame_filename, frame)\n",
    "#             frame_number += len(frame_buffer)\n",
    "#             frame_buffer = []\n",
    "    \n",
    "#     if frame_buffer:\n",
    "#         for i, frame in enumerate(frame_buffer):\n",
    "#             frame_filename = f\"{output_folder}/frame_{frame_number + i:04d}.png\"\n",
    "#             cv2.imwrite(frame_filename, frame)\n",
    "#         frame_number += len(frame_buffer)\n",
    "    \n",
    "#     cap.release()\n",
    "#     print(f\"總帧数: {frame_number}\")\n",
    "#     return frame_number\n",
    "\n",
    "# def combine_selected_frames_to_video(frames_folder, start_frame, end_frame, output_video_path, fps, frame_size):\n",
    "#     fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "#     out = cv2.VideoWriter(output_video_path, fourcc, fps, frame_size)\n",
    "\n",
    "#     for frame_number in range(start_frame, end_frame + 1):\n",
    "#         frame_filename = f\"{frames_folder}/frame_{frame_number:04d}.png\"\n",
    "#         frame = cv2.imread(frame_filename)\n",
    "#         if frame is None:\n",
    "#             break\n",
    "#         out.write(frame)\n",
    "    \n",
    "#     out.release()\n",
    "#     print(f\"总帧数: {end_frame - start_frame + 1}\")\n",
    "\n",
    "# def overwrite_frames_with_new_image(frames_folder, start_frame, end_frame, new_image_path):\n",
    "#     for frame_number in range(start_frame, end_frame + 1):\n",
    "#         frame_filename = f\"{frames_folder}/frame_{frame_number:04d}.png\"\n",
    "#         new_image = cv2.imread(new_image_path)\n",
    "#         cv2.imwrite(frame_filename, new_image)\n",
    "    \n",
    "#     print(f\"帧范围覆盖: {start_frame}到{end_frame}\")\n",
    "\n",
    "\n",
    "# def combine_frames_to_video(frames_folder, output_video_path, fps):\n",
    "#     # Combine frames to video\n",
    "#     frame_files = [f for f in os.listdir(frames_folder) if f.endswith('.png')]\n",
    "#     frame_files.sort(key=lambda x: int(x.split('_')[1].split('.')[0]))\n",
    "    \n",
    "#     if not frame_files:\n",
    "#         print(\"没有影格文件可供合成\")\n",
    "#         return\n",
    "\n",
    "#     frame = cv2.imread(os.path.join(frames_folder, frame_files[0]))\n",
    "#     height, width, _ = frame.shape\n",
    "#     fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "#     out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
    "\n",
    "#     for filename in frame_files:\n",
    "#         frame = cv2.imread(os.path.join(frames_folder, filename))\n",
    "#         out.write(frame)\n",
    "\n",
    "#     out.release()\n",
    "#     print(f\"视频已生成: {output_video_path}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def delete_frame_files(frames_folder):\n",
    "#     frame_files = [f for f in os.listdir(frames_folder) if f.endswith('.png')]\n",
    "#     for filename in frame_files:\n",
    "#         os.remove(os.path.join(frames_folder, filename))\n",
    "#     print(\"影格文件已删除\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # 读取图像\n",
    "# image = cv2.imread('G:\\\\OpenCV\\\\image\\\\1.jpg')\n",
    "\n",
    "# # 应用特效\n",
    "# result_image = apply_effect(image)\n",
    "\n",
    "# # 显示结果\n",
    "# plt.imshow(result_image)\n",
    "# plt.axis('off')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 主程式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "# 设定 ffmpeg 和 ffprobe 的路径\n",
    "os.environ[\"IMAGEIO_FFMPEG_EXE\"] = \"D:/ffmpeg/ffmpeg-master-latest-win64-gpl-shared/bin/ffmpeg.exe\"\n",
    "os.environ[\"IMAGEIO_FFPROBE_EXE\"] = \"D:/ffmpeg/ffmpeg-master-latest-win64-gpl-shared/bin/ffprobe.exe\"\n",
    "\n",
    "import subprocess\n",
    "import json\n",
    "import cv2\n",
    "from moviepy.editor import VideoFileClip, AudioFileClip\n",
    "import concurrent.futures\n",
    "\n",
    "\n",
    "\n",
    "def get_audio_format(video_path):\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            ['ffprobe', '-v', 'error', '-show_entries', 'stream=codec_type,codec_name', '-of', 'json', video_path],\n",
    "            stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True\n",
    "        )\n",
    "        \n",
    "        # 打印 ffprobe 的输出\n",
    "        print(f\"ffprobe output: {result.stdout}\")\n",
    "\n",
    "        probe = json.loads(result.stdout)\n",
    "        if 'streams' not in probe:\n",
    "            raise KeyError(\"No 'streams' key found in ffprobe output\")\n",
    "        \n",
    "        audio_streams = [stream for stream in probe['streams'] if stream['codec_type'] == 'audio']\n",
    "        if not audio_streams:\n",
    "            return \"aac\"  # Default to AAC if no audio stream is found\n",
    "        \n",
    "        audio_format = audio_streams[0]['codec_name']\n",
    "        return audio_format\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "        raise e\n",
    "\n",
    "def get_audio(video_path, audio_path, audio_format):\n",
    "    print(f\"视频路径: {video_path}\")\n",
    "    print(f\"文件存在: {os.path.exists(video_path)}\")\n",
    "    video = VideoFileClip(video_path)\n",
    "    video.audio.write_audiofile(audio_path, codec=audio_format)\n",
    "\n",
    "def add_audio_to_video(video_path, audio_path, output_path):\n",
    "    try:\n",
    "        video = VideoFileClip(video_path)\n",
    "        audio = AudioFileClip(audio_path)\n",
    "        \n",
    "        # Ensure the audio duration matches the video duration\n",
    "        audio = audio.set_duration(video.duration)\n",
    "        \n",
    "        final_video = video.set_audio(audio)\n",
    "        fps = video.fps if video.fps else 30  # Set default FPS to 30 if not detected\n",
    "        \n",
    "        final_video.write_videofile(output_path, codec='libx264', audio_codec='aac', fps=fps)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Function to get video information\n",
    "def get_video_info(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        cap.release()\n",
    "        raise ValueError(\"无法读取视频信息\")\n",
    "    \n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    cap.release()\n",
    "    \n",
    "    frame_info = {\n",
    "        \"color\": 'RGB' if frame.shape[2] == 3 else 'Grayscale',\n",
    "        \"shape\": frame.shape,\n",
    "        \"ndim\": len(frame.shape),\n",
    "        \"size\": frame.shape[0] * frame.shape[1],\n",
    "        \"dtype\": f\"{frame.dtype}-bit\",\n",
    "        \"type\": str(type(frame)),\n",
    "        \"total_frames\": total_frames,\n",
    "        \"fps\": fps  # 添加 fps 字段\n",
    "    }\n",
    "    return frame_info\n",
    "\n",
    "\n",
    "def get_total_frames(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    cap.release()\n",
    "    return total_frames\n",
    "\n",
    "\n",
    "def get_fps_cv2(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    cap.release()\n",
    "    return fps\n",
    "\n",
    "def get_fps_ffprobe(video_path):\n",
    "    result = subprocess.run(\n",
    "        ['ffprobe', '-v', 'error', '-select_streams', 'v:0', '-show_entries', 'stream=r_frame_rate', '-of', 'json', video_path],\n",
    "        stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True\n",
    "    )\n",
    "    \n",
    "    probe = json.loads(result.stdout)\n",
    "    fps_str = probe['streams'][0]['r_frame_rate']\n",
    "    num, den = map(int, fps_str.split('/'))\n",
    "    fps = num / den\n",
    "    return fps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 處理照片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoClip\n",
    "from moviepy.editor import VideoFileClip, AudioFileClip\n",
    "\n",
    "def process_video_with_effects(video_path, effects):\n",
    "    # 加载视频帧到内存\n",
    "    frames, time_indices = load_frames_to_memory(video_path)\n",
    "    if frames is None:\n",
    "        return False\n",
    "    \n",
    "    # 检查内存中加载的帧数量是否与视频文件中的一致\n",
    "    if not compare_frames_in_memory(frames, video_path):\n",
    "        return False\n",
    "    \n",
    "    # 根据特效替换内存中的视频帧\n",
    "    replace_frames_in_memory(frames, effects)\n",
    "    \n",
    "    # 保存处理后的视频\n",
    "    save_processed_video(frames, time_indices, video_path)\n",
    "\n",
    "    return True\n",
    "\n",
    "def save_processed_video(frames, time_indices, output_path, fps):\n",
    "    def make_frame(t):\n",
    "        # 根据时间索引返回对应的帧\n",
    "        index = int(t * fps)\n",
    "        return frames[index]\n",
    "\n",
    "    # 创建自定义视频剪辑\n",
    "    video_clip = VideoClip(make_frame, duration=len(frames) / fps)\n",
    "\n",
    "    # 保存处理后的视频\n",
    "    video_clip.write_videofile(output_path, fps=fps, codec='libx264', audio=False)\n",
    "\n",
    "def replace_frames_in_memory(frames, effects):\n",
    "    for (start_min, start_sec, end_min, end_sec), func in effects.items():\n",
    "        start_time = start_min * 60 + start_sec\n",
    "        end_time = end_min * 60 + end_sec\n",
    "        \n",
    "        fps = get_fps_cv2(video_path)\n",
    "        start_frame_index = int(start_time * fps)\n",
    "        end_frame_index = int(end_time * fps)\n",
    "\n",
    "        for i in range(start_frame_index, end_frame_index + 1):\n",
    "            frames[i] = process_frame(frames[i], func)\n",
    "    \n",
    "    return frames  # 返回修改后的帧列表\n",
    "\n",
    "def process_frame(frame, effect_func):\n",
    "    if effect_func:\n",
    "        return effect_func(frame)\n",
    "    return frame\n",
    "def compare_frames_in_memory(frames, video_path):\n",
    "    total_frames = get_total_frames(video_path)\n",
    "    fps = get_fps_cv2(video_path)  # 获取视频的帧率\n",
    "    if abs(len(frames) / fps - total_frames / fps) < 1:  # 比较帧数量差值的绝对值是否小于1秒\n",
    "        print(\"视频帧数量核对成功\")\n",
    "        return True\n",
    "    else:\n",
    "        print(\"视频帧数量核对不成功\")\n",
    "        del frames  # 清理帧列表\n",
    "        return False\n",
    "\n",
    "\n",
    "\n",
    "def load_frames_to_memory(video_path):\n",
    "    try:\n",
    "        clip = VideoFileClip(video_path)\n",
    "        fps = clip.fps\n",
    "        frames = []\n",
    "        time_indices = []\n",
    "        for t, frame in clip.iter_frames(with_times=True, fps=fps):\n",
    "            frames.append(frame)\n",
    "            time_indices.append(t)\n",
    "        clip.close()\n",
    "        return frames, time_indices\n",
    "    except Exception as e:\n",
    "        print(f\"加载视频帧失败: {e}\")\n",
    "        return None, None\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特效"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 修改後的效果函數，這些函數現在直接處理影格\n",
    "import numpy as np\n",
    "import dlib\n",
    "\n",
    "def convert_to_grayscale(frame):\n",
    "    # 转换为灰度图像\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # 将灰度值应用到每个通道上\n",
    "    bgr_frame = np.zeros_like(frame)\n",
    "    bgr_frame[:,:,0] = gray_frame  # 将灰度值应用到蓝色通道\n",
    "    bgr_frame[:,:,1] = gray_frame  # 将灰度值应用到绿色通道\n",
    "    bgr_frame[:,:,2] = gray_frame  # 将灰度值应用到红色通道\n",
    "    \n",
    "    return bgr_frame\n",
    "\n",
    "def apply_laplacian(frame):\n",
    "    laplacian = cv2.Laplacian(frame, cv2.CV_64F)\n",
    "    return cv2.convertScaleAbs(laplacian)\n",
    "\n",
    "def rotate_image(frame):\n",
    "    rows, cols, _ = frame.shape\n",
    "    M = cv2.getRotationMatrix2D((cols / 2, rows / 2), 10, 10)\n",
    "    return cv2.warpAffine(frame, M, (cols, rows))\n",
    "\n",
    "def bgr_to_rgb(frame):\n",
    "    return cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "\n",
    "def apply_smiley_effect(frame):\n",
    "    # 使用 dlib 进行人脸检测\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    face_rects, _, _ = detector.run(frame, 1, -0)\n",
    "\n",
    "    # 加载笑脸图片（假设为 PNG 格式，带 alpha 通道）\n",
    "    smiley = cv2.imread('smiley.png', cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "    # 遍历检测到的人脸\n",
    "    for d in face_rects:\n",
    "        x1, y1, x2, y2 = d.left(), d.top(), d.right(), d.bottom()\n",
    "        face_width = x2 - x1\n",
    "        face_height = y2 - y1\n",
    "        \n",
    "        # 调整笑脸大小以适应检测到的人脸\n",
    "        resized_smiley = cv2.resize(smiley, (face_width, face_height))\n",
    "\n",
    "        # 将笑脸叠加到帧上\n",
    "        for row in range(face_height):\n",
    "            for col in range(face_width):\n",
    "                if resized_smiley[row, col, 3] != 0:  # 检查 alpha 通道\n",
    "                    frame[y1 + row, x1 + col] = resized_smiley[row, col, :3]  # 设置图像像素值\n",
    "                    \n",
    "    return frame\n",
    "\n",
    "\n",
    "def apply_laplacian_and_hsv_mask(frame):\n",
    "    # 将图像转换为 HSV 色彩空间\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # 定义肤色区域的 HSV 范围\n",
    "    minSkin = np.array([0, 30, 60])   # HSV 最小值\n",
    "    maxSkin = np.array([25, 150, 255])   # HSV 最大值\n",
    "\n",
    "    # 创建肤色掩码\n",
    "    mask_skin = cv2.inRange(hsv, minSkin, maxSkin)\n",
    "    \n",
    "    # 使用拉普拉斯边缘检测对图像进行处理\n",
    "    laplacian = cv2.Laplacian(frame, cv2.CV_64F)\n",
    "    \n",
    "    # 将拉普拉斯边缘检测结果与肤色掩码相乘\n",
    "    masked_laplacian = cv2.bitwise_and(laplacian, laplacian, mask=mask_skin)\n",
    "    \n",
    "    # 创建一个与输入图像相同大小的空白图像\n",
    "    result = np.zeros_like(frame, dtype=np.uint8)\n",
    "    \n",
    "    # 将拉普拉斯边缘检测结果与输入图像相加\n",
    "    result = cv2.addWeighted(frame, 0.5, masked_laplacian, 0.5, 0)\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def convert_to_quarters(frame):\n",
    "    # 将图像大小减小到原始大小的四分之一\n",
    "    resized_frame = cv2.resize(frame, (frame.shape[1] // 2, frame.shape[0] // 2))\n",
    "    \n",
    "    # 将四个四分之一大小的图像组合成一个新的图像\n",
    "    top_left = resized_frame\n",
    "    top_right = np.fliplr(resized_frame)  # 水平翻转\n",
    "    bottom_left = np.flipud(resized_frame)  # 垂直翻转\n",
    "    bottom_right = np.flipud(np.fliplr(resized_frame))  # 水平和垂直翻转\n",
    "    \n",
    "    # 创建一个新的图像，将四个图像组合在一起\n",
    "    new_frame = np.zeros((frame.shape[0], frame.shape[1], frame.shape[2]), dtype=np.uint8)\n",
    "    new_frame[:resized_frame.shape[0], :resized_frame.shape[1]] = top_left\n",
    "    new_frame[:resized_frame.shape[0], resized_frame.shape[1]:] = top_right\n",
    "    new_frame[resized_frame.shape[0]:, :resized_frame.shape[1]] = bottom_left\n",
    "    new_frame[resized_frame.shape[0]:, resized_frame.shape[1]:] = bottom_right\n",
    "    \n",
    "    return new_frame\n",
    "\n",
    "\n",
    "def apply_effect(image):\n",
    "    # Split the image into its three channels\n",
    "    b, g, r = cv2.split(image)\n",
    "    \n",
    "    # Apply histogram equalization to each color channel\n",
    "    b_eq = cv2.equalizeHist(b)\n",
    "    g_eq = cv2.equalizeHist(g)\n",
    "    r_eq = cv2.equalizeHist(r)\n",
    "    \n",
    "    # Merge the equalized color channels into a color image\n",
    "    equ_color = cv2.merge((b_eq, g_eq, r_eq))\n",
    "    \n",
    "    # Convert the color image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Resize the grayscale image to one quarter of its original size\n",
    "    resized_gray = cv2.resize(gray, (gray.shape[1] // 2, gray.shape[0] // 2))\n",
    "    \n",
    "    # Apply histogram equalization to the resized grayscale image\n",
    "    equ_gray = cv2.equalizeHist(resized_gray)\n",
    "    \n",
    "    # Convert the grayscale image to a color image with three channels\n",
    "    equ_gray_bgr = cv2.cvtColor(equ_gray, cv2.COLOR_GRAY2BGR)\n",
    "    \n",
    "    # Resize the color image to the size of the resized grayscale image\n",
    "    equ_color_resized = cv2.resize(equ_color, (resized_gray.shape[1], resized_gray.shape[0]))\n",
    "    \n",
    "    # Create the final composition\n",
    "    final_result = np.zeros((max(resized_gray.shape[0], equ_color_resized.shape[0]) * 2, max(resized_gray.shape[1], equ_color_resized.shape[1]) * 2, 3), dtype=np.uint8)\n",
    "    \n",
    "    # Arrange the images in the final composition\n",
    "    final_result[:resized_gray.shape[0], :resized_gray.shape[1]] = equ_gray_bgr  # Top left\n",
    "    final_result[:resized_gray.shape[0], resized_gray.shape[1]:] = equ_color_resized  # Top right\n",
    "    final_result[resized_gray.shape[0]:, :resized_gray.shape[1]] = cv2.flip(equ_gray_bgr, 0)  # Bottom left (flip vertically)\n",
    "    final_result[resized_gray.shape[0]:, resized_gray.shape[1]:] = cv2.flip(equ_color_resized, 0)  # Bottom right (flip vertically)\n",
    "    \n",
    "    return final_result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 執行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "视频文件存在: True\n",
      "音频文件存在: False\n",
      "视频文件存在: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# 调用函数运行主程序\n",
    "video_path = './process_video0601/input_video/new-version-with-lyrics-alan-a-lan-qian-gu-qiangu-meng-huan-xi-you-dian-nao-ban-official-mv-2023-7-25.mp4'\n",
    "processed_video_path = './process_video0601/processed_video/processed_video.mp4'\n",
    "final_video_path = './process_video0601/final_video_with_audio/final_video_with_audio.mp4'\n",
    "audio_path = './process_video0601/extracted_audio/extracted_audio22'\n",
    "\n",
    "# 检查文件路径是否存在\n",
    "print(\"视频文件存在:\", os.path.exists(video_path))\n",
    "print(\"音频文件存在:\", os.path.exists(audio_path))\n",
    "print(\"视频文件存在:\", os.path.exists(processed_video_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "帧率 (cv2): 25.0\n",
      "帧率 (ffprobe): 25.0\n",
      "ffprobe output: {\n",
      "    \"programs\": [\n",
      "\n",
      "    ],\n",
      "    \"stream_groups\": [\n",
      "\n",
      "    ],\n",
      "    \"streams\": [\n",
      "        {\n",
      "            \"codec_name\": \"h264\",\n",
      "            \"codec_type\": \"video\"\n",
      "        },\n",
      "        {\n",
      "            \"codec_name\": \"aac\",\n",
      "            \"codec_type\": \"audio\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# 获取视频帧率\n",
    "fps_cv2 = get_fps_cv2(video_path)\n",
    "ffprobe=get_fps_ffprobe(video_path)\n",
    "print(f\"帧率 (cv2): {fps_cv2}\")\n",
    "print(f\"帧率 (ffprobe): {ffprobe}\")\n",
    "\n",
    "\n",
    "\n",
    "audio_format = get_audio_format(video_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "视频路径: ./process_video0601/input_video/new-version-with-lyrics-alan-a-lan-qian-gu-qiangu-meng-huan-xi-you-dian-nao-ban-official-mv-2023-7-25.mp4\n",
      "文件存在: True\n",
      "MoviePy - Writing audio in ./process_video0601/extracted_audio/extracted_audio22.aac\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# 提取音频\n",
    "\n",
    "get_audio(video_path, f\"{audio_path}.{audio_format}\", audio_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'color': 'RGB', 'shape': (480, 854, 3), 'ndim': 3, 'size': 409920, 'dtype': 'uint8-bit', 'type': \"<class 'numpy.ndarray'>\", 'total_frames': 5123, 'fps': 25.0}\n"
     ]
    }
   ],
   "source": [
    "# 提取影像資訊\n",
    "video_info = get_video_info(video_path)\n",
    "print(video_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载到内存中的帧数: 5124\n",
      "视频文件中的总帧数: 5123\n",
      "视频帧数量核对成功\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "frames, time_indices = load_frames_to_memory(video_path)\n",
    "print(\"加载到内存中的帧数:\", len(frames))\n",
    "print(\"视频文件中的总帧数:\", get_total_frames(video_path))\n",
    "compare_frames_in_memory(frames, video_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[74], line 11\u001b[0m\n\u001b[0;32m      1\u001b[0m effects \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      2\u001b[0m         (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m30\u001b[39m): apply_effect,\n\u001b[0;32m      3\u001b[0m         (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m): convert_to_grayscale,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m         \n\u001b[0;32m      9\u001b[0m         }\n\u001b[1;32m---> 11\u001b[0m \u001b[43mreplace_frames_in_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffects\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m frames \u001b[38;5;241m=\u001b[39mreplace_frames_in_memory(frames, effects)\n\u001b[0;32m     13\u001b[0m compare_frames_in_memory(frames, video_path)\n",
      "Cell \u001b[1;32mIn[67], line 44\u001b[0m, in \u001b[0;36mreplace_frames_in_memory\u001b[1;34m(frames, effects)\u001b[0m\n\u001b[0;32m     41\u001b[0m     end_frame_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(end_time \u001b[38;5;241m*\u001b[39m fps)\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_frame_index, end_frame_index \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m---> 44\u001b[0m         frames[i] \u001b[38;5;241m=\u001b[39m process_frame(\u001b[43mframes\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m, func)\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frames\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "effects = {\n",
    "        (3, 0, 3, 30): apply_effect,\n",
    "        (0, 30, 1, 0): convert_to_grayscale,\n",
    "        (1, 0, 1, 30): apply_laplacian,\n",
    "        (1, 30, 2, 0): rotate_image,\n",
    "        (2, 0, 2, 30): bgr_to_rgb,\n",
    "        (2, 30, 3, 0): convert_to_quarters,\n",
    "        \n",
    "        }\n",
    "\n",
    "replace_frames_in_memory(frames, effects)\n",
    "frames =replace_frames_in_memory(frames, effects)\n",
    "compare_frames_in_memory(frames, video_path)\n",
    "save_processed_video(frames, time_indices, processed_video_path, fps_cv2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video ./process_video0601/final_video_with_audio/final_video_with_audio.mp4.\n",
      "MoviePy - Writing audio in final_video_with_audioTEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video ./process_video0601/final_video_with_audio/final_video_with_audio.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ./process_video0601/final_video_with_audio/final_video_with_audio.mp4\n"
     ]
    }
   ],
   "source": [
    "add_audio_to_video(\"G:\\\\OpenCV\\\\process_video0601\\\\processed_video\\\\processed_video.mp4\",\"G:\\\\OpenCV\\\\process_video0601\\\\extracted_audio\\\\extracted_audio22.aac\", final_video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
